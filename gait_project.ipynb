{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f490de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Anuj bahadur kamble\n"
     ]
    }
   ],
   "source": [
    "print('Hello Anuj bahadur kamble')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5bb91d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2249d948-8462-4309-9aaa-86bd38d89228",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a465ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abnormal', 'dance', 'exercise', 'normal', 'yoga']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "dataset_path = os.listdir('dataset1/train')\n",
    "label_types=os.listdir('dataset1/train')\n",
    "print(label_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03336adb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tag                                         video_name\n",
      "0  abnormal  dataset1/train/abnormal/Abnormal Gait Exam _ A...\n",
      "1  abnormal  dataset1/train/abnormal/Abnormal Gait Exam _ N...\n",
      "2  abnormal         dataset1/train/abnormal/abnormal-gait.webp\n",
      "3  abnormal  dataset1/train/abnormal/WhatsApp Video 2024-03...\n",
      "4  abnormal  dataset1/train/abnormal/WhatsApp Video 2024-03...\n",
      "       tag                                         video_name\n",
      "38  normal                   dataset1/train/normal/snehal.mp4\n",
      "39    yoga  dataset1/train/yoga/10_MIN_LOWER_BODY_STRETCH_...\n",
      "40    yoga  dataset1/train/yoga/15_Min._Full_Body_Stretch_...\n",
      "41    yoga  dataset1/train/yoga/Best_Yoga_Shilpa_Shetty_Vi...\n",
      "42    yoga  dataset1/train/yoga/Face_Yoga_for_GLOWING_SKIN...\n"
     ]
    }
   ],
   "source": [
    "#Preparing Training Data\n",
    "\n",
    "rooms = []\n",
    "for item in dataset_path:\n",
    "    # get all the file names\n",
    "    all_rooms = os.listdir('dataset1/train' + '/' +item)\n",
    "    \n",
    "    #Add them to the list\n",
    "    for room in all_rooms:\n",
    "        rooms.append((item,str('dataset1/train' + '/' +item) + '/' + room))\n",
    "#Build a dataframe\n",
    "train_df = pd.DataFrame(data=rooms,columns=['tag','video_name'])\n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3060ecd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = train_df.loc[:,['video_name','tag']]\n",
    "df\n",
    "df.to_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace7d435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abnormal', 'dance', 'exercise', 'normal', 'yoga']\n",
      "Types of activities found :  5\n",
      "        tag                                         video_name\n",
      "0  abnormal  dataset1/test/abnormal/WhatsApp Video 2024-04-...\n",
      "1     dance  dataset1/test/dance/WhatsApp Video 2024-04-09 ...\n",
      "2  exercise  dataset1/test/exercise/WhatsApp Video 2024-04-...\n",
      "3    normal  dataset1/test/normal/WhatsApp Video 2024-04-09...\n",
      "4      yoga  dataset1/test/yoga/WhatsApp Video 2024-04-09 a...\n",
      "        tag                                         video_name\n",
      "0  abnormal  dataset1/test/abnormal/WhatsApp Video 2024-04-...\n",
      "1     dance  dataset1/test/dance/WhatsApp Video 2024-04-09 ...\n",
      "2  exercise  dataset1/test/exercise/WhatsApp Video 2024-04-...\n",
      "3    normal  dataset1/test/normal/WhatsApp Video 2024-04-09...\n",
      "4      yoga  dataset1/test/yoga/WhatsApp Video 2024-04-09 a...\n"
     ]
    }
   ],
   "source": [
    "#preparing Test Data\n",
    "\n",
    "dataset_path = os.listdir('dataset1/test')\n",
    "print(dataset_path)\n",
    "\n",
    "room_types = os.listdir('dataset1/test')\n",
    "print('Types of activities found : ',len(dataset_path))\n",
    "\n",
    "rooms=[]\n",
    "\n",
    "for item in dataset_path:\n",
    "    #get all the file names\n",
    "    all_rooms = os.listdir('dataset1/test' + '/' +item)\n",
    "    \n",
    "    #Add them to the list\n",
    "    for room in all_rooms:\n",
    "        rooms.append((item,str('dataset1/test' + '/' + item) + '/' + room))\n",
    "#build a dataframe\n",
    "test_df = pd.DataFrame(data = rooms , columns =['tag','video_name'])\n",
    "print(test_df.head())\n",
    "print(test_df.tail())\n",
    "\n",
    "df = test_df.loc[:,['video_name','tag']]\n",
    "df\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "317e2231",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to c:\\users\\rushab\\appdata\\local\\temp\\pip-req-build-1eihf3uk\n",
      "  Resolved https://github.com/tensorflow/docs to commit 8b36191001b53bfce4fe15b77e243fbd7f382e41\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: astor in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-docs==2024.2.5.73858) (0.8.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-docs==2024.2.5.73858) (2.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-docs==2024.2.5.73858) (3.1.2)\n",
      "Requirement already satisfied: nbformat in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-docs==2024.2.5.73858) (5.9.2)\n",
      "Requirement already satisfied: protobuf>=3.12 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-docs==2024.2.5.73858) (4.23.4)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-docs==2024.2.5.73858) (6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->tensorflow-docs==2024.2.5.73858) (2.1.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (5.3.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (5.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.2.5.73858) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.2.5.73858) (0.18.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core->nbformat->tensorflow-docs==2024.2.5.73858) (3.0.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat->tensorflow-docs==2024.2.5.73858) (305.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs 'C:\\Users\\RUSHAB\\AppData\\Local\\Temp\\pip-req-build-1eihf3uk'\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ac5fca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39a23e38",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mutils in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (1.0.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from mutils) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9ade2ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imutils in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "176f4f82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    }
   ],
   "source": [
    "!pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0757fdec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\users\\rushab\\appdata\\roaming\\python\\python311\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eebe86c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\RUSHAB\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de957354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "           gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 5120)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e9cf90f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training : 43\n",
      "Total videos for testing : 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>dataset1/train/yoga/Best_Yoga_Shilpa_Shetty_Vi...</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>dataset1/train/abnormal/WhatsApp Video 2024-03...</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>dataset1/train/dance/Twist_____Basic_Dance_Ste...</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>dataset1/train/yoga/Face_Yoga_for_GLOWING_SKIN...</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>dataset1/train/abnormal/WhatsApp Video 2024-03...</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>dataset1/train/dance/Badtameez_Dil___Easy_Danc...</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>dataset1/train/dance/Dance_Tutorial_#dancetuto...</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>dataset1/train/abnormal/WhatsApp Video 2024-03...</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>dataset1/train/exercise/Why your hips are tigh...</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>dataset1/train/yoga/10_MIN_LOWER_BODY_STRETCH_...</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                         video_name       tag\n",
       "41          41  dataset1/train/yoga/Best_Yoga_Shilpa_Shetty_Vi...      yoga\n",
       "10          10  dataset1/train/abnormal/WhatsApp Video 2024-03...  abnormal\n",
       "24          24  dataset1/train/dance/Twist_____Basic_Dance_Ste...     dance\n",
       "42          42  dataset1/train/yoga/Face_Yoga_for_GLOWING_SKIN...      yoga\n",
       "6            6  dataset1/train/abnormal/WhatsApp Video 2024-03...  abnormal\n",
       "19          19  dataset1/train/dance/Badtameez_Dil___Easy_Danc...     dance\n",
       "20          20  dataset1/train/dance/Dance_Tutorial_#dancetuto...     dance\n",
       "13          13  dataset1/train/abnormal/WhatsApp Video 2024-03...  abnormal\n",
       "37          37  dataset1/train/exercise/Why your hips are tigh...  exercise\n",
       "39          39  dataset1/train/yoga/10_MIN_LOWER_BODY_STRETCH_...      yoga"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(f'Total videos for training : {len(train_df)}')\n",
    "print(f'Total videos for testing : {len(test_df)}')\n",
    "\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f63c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMG_SIZE= 224\n",
    "def crop_center_square(frame):\n",
    "    y,x = frame.shape[0.2]\n",
    "    min_dim = min(y,x)\n",
    "    start_x = (x//2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim //2)\n",
    "    return frame[start_y : start_y + min_dim ,start_x : start_x +min_dim]\n",
    "\n",
    "def load_video(path, max_frames=0, resize =(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret,frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:,:,[2,1,0]]\n",
    "            frames.append(frame)\n",
    "            if len(frames == max_frames):\n",
    "                   break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf33621c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\RUSHAB\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\RUSHAB\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "         weights='imagenet',\n",
    "         include_top=False,\n",
    "         pooling='avg',\n",
    "         input_shape=(IMG_SIZE, IMG_SIZE,3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "    \n",
    "    inputs = keras.Input((IMG_SIZE,IMG_SIZE,3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "    \n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs,outputs, name='feature_extractor')\n",
    "feature_extractor = build_feature_extractor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "098e5534",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\RUSHAB\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "['abnormal', 'dance', 'exercise', 'normal', 'yoga']\n",
      "WARNING:tensorflow:From C:\\Users\\RUSHAB\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(num_oov_indices=0,vocabulary=np.unique(train_df['tag']))\n",
    "print(label_processor.get_vocabulary())\n",
    "\n",
    "labels = train_df['tag'].values\n",
    "labels = label_processor(labels[...,None]).numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40c5ea0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Hyperparameter\n",
    "IMG_SIZE=224\n",
    "BATCH_SIZE=64\n",
    "EPOCHS=100\n",
    "\n",
    "MAX_SEQ_LENGTH =20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93cc5cac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame feature in train set:(43, 20, 2048)\n",
      "frame masks in train set:(43, 20)\n",
      "train_labels in train set:(43, 1)\n",
      "test_labels in train set: (5, 1)\n"
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df,root_dir):\n",
    "    num_samples= len(df)\n",
    "    video_paths = df['video_name'].values.tolist()\n",
    "    \n",
    "    ## take all classlabels from train_df column named 'tag' and store in labels\n",
    "    labels = df['tag'].values\n",
    "    \n",
    "    #convert claslabels to label encoding\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "    \n",
    "    #frame_masks and frame_feture are hat e ill feed to our sequence model\n",
    "    #frame_masks ill contain a bunch of booleans denoting if a timestamp is \n",
    "    #masked ith padding or not\n",
    "    \n",
    "    frame_masks = np.zeros(shape=(num_samples,MAX_SEQ_LENGTH),dtype='bool')\n",
    "    frame_features = np.zeros(shape =(num_samples,MAX_SEQ_LENGTH,NUM_FEATURES),dtype='float32')\n",
    "    \n",
    "    #for each video\n",
    "    for idx,path in enumerate(video_paths):\n",
    "        #gather all its frames and add a batch dimension\n",
    "        frames = load_video(os.path.join(root_dir,path))\n",
    "        frames = frames[None,...]\n",
    "        # Initialize placrholder to store the mask and feature of the current video\n",
    "        temp_frame_mask = np.zeros(shape=(1,MAX_SEQ_LENGTH,),dtype='bool')\n",
    "        temp_frame_features = np.zeros(\n",
    "          shape=(1,MAX_SEQ_LENGTH, NUM_FEATURES),dtype='float32')\n",
    "        \n",
    "        #extract feature from the frames of the current video\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i,j,:]= feature_extractor.predict(\n",
    "                   batch[None,j,:])\n",
    "            temp_frame_mask[i,:length]=1 # 1= not masked, 0 = masked\n",
    "        frame_features[idx,]= temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "        \n",
    "    return(frame_features, frame_masks),labels\n",
    "\n",
    "train_data,train_labels = prepare_all_videos(train_df,'train')\n",
    "test_data,test_labels = prepare_all_videos(test_df,'test')\n",
    "\n",
    "print(f'frame feature in train set:{train_data[0].shape}')\n",
    "print(f'frame masks in train set:{train_data[1].shape}')\n",
    "\n",
    "print(f'train_labels in train set:{train_labels.shape}')\n",
    "print(f'test_labels in train set: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "953fa37d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    num_samples= len(df)\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES),dtype='float32')\n",
    "    \n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH),dtype='bool')\n",
    "    \n",
    "    x= keras.layers.GRU(16,return_sequences=True)(frame_features_input,mask=mask_input)\n",
    "    x= keras.layers.GRU(8)(x)\n",
    "    x= keras.layers.Dropout(0.4)(x)\n",
    "    x= keras.layers.Dense(8,activation='relu')(x)\n",
    "    output= keras.layers.Dense(len(class_vocab),activation='softmax')(x)\n",
    "    \n",
    "    rnn_model = keras.Model([frame_features_input,mask_input],output)\n",
    "    \n",
    "    rnn_model.compile(\n",
    "            loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return rnn_model\n",
    "EPOCHS = 50\n",
    "\n",
    "#utility for running experiments.\n",
    "\n",
    "\n",
    "#def run_experiment():\n",
    " #    filepath='./tmp/video_classifier'\n",
    "  #   checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "   #  filepath,save_weights_only=True, save_best_only=True,verbose=1)\n",
    "   \n",
    "  #   seq_model = get_sequence_model()\n",
    "  #   history = seq_model.fit(\n",
    "  #     [train_data[0],train_data[1]],\n",
    "  #     train_labels,\n",
    "   #    validation_split=0.3,\n",
    "   #    epochs=EPOCHS,\n",
    "    #   callbacks=[checkpoint],)\n",
    "  #  seq_model.load_weights(filepath)\n",
    "  #  _,accuracy = seq_model.evaluate([test_data[0],test_data[1]],test_labels)\n",
    "  #  print(f'test accuracy: {round(accuracy * 100,2)}%')\n",
    "    \n",
    "  #   return history, seq_model\n",
    "#_,sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "160bff02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\RUSHAB\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\RUSHAB\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6094 - accuracy: 0.6000\n",
      "Epoch 1: val_loss improved from inf to 1.61024, saving model to ./tmp\\video_classifier\n",
      "1/1 [==============================] - 28s 28s/step - loss: 1.6094 - accuracy: 0.6000 - val_loss: 1.6102 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6086 - accuracy: 0.6000\n",
      "Epoch 2: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.6086 - accuracy: 0.6000 - val_loss: 1.6110 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6077 - accuracy: 0.6000\n",
      "Epoch 3: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.6077 - accuracy: 0.6000 - val_loss: 1.6118 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6068 - accuracy: 0.6000\n",
      "Epoch 4: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.6068 - accuracy: 0.6000 - val_loss: 1.6126 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6060 - accuracy: 0.6000\n",
      "Epoch 5: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.6060 - accuracy: 0.6000 - val_loss: 1.6134 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6051 - accuracy: 0.6000\n",
      "Epoch 6: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.6051 - accuracy: 0.6000 - val_loss: 1.6143 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6043 - accuracy: 0.6000\n",
      "Epoch 7: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.6043 - accuracy: 0.6000 - val_loss: 1.6151 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6034 - accuracy: 0.6000\n",
      "Epoch 8: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.6034 - accuracy: 0.6000 - val_loss: 1.6159 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6025 - accuracy: 0.6000\n",
      "Epoch 9: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.6025 - accuracy: 0.6000 - val_loss: 1.6167 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6017 - accuracy: 0.6000\n",
      "Epoch 10: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.6017 - accuracy: 0.6000 - val_loss: 1.6175 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6008 - accuracy: 0.6000\n",
      "Epoch 11: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.6008 - accuracy: 0.6000 - val_loss: 1.6183 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6000 - accuracy: 0.6000\n",
      "Epoch 12: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.6000 - accuracy: 0.6000 - val_loss: 1.6191 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5991 - accuracy: 0.6000\n",
      "Epoch 13: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.5991 - accuracy: 0.6000 - val_loss: 1.6199 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5983 - accuracy: 0.6000\n",
      "Epoch 14: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.5983 - accuracy: 0.6000 - val_loss: 1.6207 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5974 - accuracy: 0.6000\n",
      "Epoch 15: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.5974 - accuracy: 0.6000 - val_loss: 1.6215 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5966 - accuracy: 0.6000\n",
      "Epoch 16: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.5966 - accuracy: 0.6000 - val_loss: 1.6223 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5957 - accuracy: 0.6000\n",
      "Epoch 17: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.5957 - accuracy: 0.6000 - val_loss: 1.6231 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5949 - accuracy: 0.6000\n",
      "Epoch 18: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.5949 - accuracy: 0.6000 - val_loss: 1.6239 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5940 - accuracy: 0.6000\n",
      "Epoch 19: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.5940 - accuracy: 0.6000 - val_loss: 1.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5932 - accuracy: 0.6000\n",
      "Epoch 20: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 1.5932 - accuracy: 0.6000 - val_loss: 1.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5923 - accuracy: 0.6000\n",
      "Epoch 21: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.5923 - accuracy: 0.6000 - val_loss: 1.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5915 - accuracy: 0.6000\n",
      "Epoch 22: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.5915 - accuracy: 0.6000 - val_loss: 1.6271 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5906 - accuracy: 0.6000\n",
      "Epoch 23: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.5906 - accuracy: 0.6000 - val_loss: 1.6280 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5898 - accuracy: 0.6000\n",
      "Epoch 24: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 1.5898 - accuracy: 0.6000 - val_loss: 1.6288 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5890 - accuracy: 0.6000\n",
      "Epoch 25: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.5890 - accuracy: 0.6000 - val_loss: 1.6296 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5881 - accuracy: 0.6000\n",
      "Epoch 26: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.5881 - accuracy: 0.6000 - val_loss: 1.6304 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5873 - accuracy: 0.6000\n",
      "Epoch 27: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.5873 - accuracy: 0.6000 - val_loss: 1.6312 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5864 - accuracy: 0.6000\n",
      "Epoch 28: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.5864 - accuracy: 0.6000 - val_loss: 1.6320 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5856 - accuracy: 0.6000\n",
      "Epoch 29: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.5856 - accuracy: 0.6000 - val_loss: 1.6328 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5848 - accuracy: 0.6000\n",
      "Epoch 30: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.5848 - accuracy: 0.6000 - val_loss: 1.6336 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5839 - accuracy: 0.6000\n",
      "Epoch 31: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.5839 - accuracy: 0.6000 - val_loss: 1.6344 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5831 - accuracy: 0.6000\n",
      "Epoch 32: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.5831 - accuracy: 0.6000 - val_loss: 1.6352 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5823 - accuracy: 0.6000\n",
      "Epoch 33: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.5823 - accuracy: 0.6000 - val_loss: 1.6360 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5815 - accuracy: 0.6000\n",
      "Epoch 34: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.5815 - accuracy: 0.6000 - val_loss: 1.6368 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5806 - accuracy: 0.6000\n",
      "Epoch 35: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.5806 - accuracy: 0.6000 - val_loss: 1.6376 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5798 - accuracy: 0.6000\n",
      "Epoch 36: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.5798 - accuracy: 0.6000 - val_loss: 1.6384 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5790 - accuracy: 0.6000\n",
      "Epoch 37: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.5790 - accuracy: 0.6000 - val_loss: 1.6392 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5782 - accuracy: 0.6000\n",
      "Epoch 38: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.5782 - accuracy: 0.6000 - val_loss: 1.6400 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5773 - accuracy: 0.6000\n",
      "Epoch 39: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.5773 - accuracy: 0.6000 - val_loss: 1.6407 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5765 - accuracy: 0.6000\n",
      "Epoch 40: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.5765 - accuracy: 0.6000 - val_loss: 1.6415 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5757 - accuracy: 0.6000\n",
      "Epoch 41: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.5757 - accuracy: 0.6000 - val_loss: 1.6423 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5749 - accuracy: 0.6000\n",
      "Epoch 42: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.5749 - accuracy: 0.6000 - val_loss: 1.6431 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5741 - accuracy: 0.6000\n",
      "Epoch 43: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.5741 - accuracy: 0.6000 - val_loss: 1.6439 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5732 - accuracy: 0.6000\n",
      "Epoch 44: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.5732 - accuracy: 0.6000 - val_loss: 1.6447 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5724 - accuracy: 0.6000\n",
      "Epoch 45: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.5724 - accuracy: 0.6000 - val_loss: 1.6455 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5716 - accuracy: 0.6000\n",
      "Epoch 46: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.5716 - accuracy: 0.6000 - val_loss: 1.6463 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5708 - accuracy: 0.6000\n",
      "Epoch 47: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.5708 - accuracy: 0.6000 - val_loss: 1.6471 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5700 - accuracy: 0.6000\n",
      "Epoch 48: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.5700 - accuracy: 0.6000 - val_loss: 1.6478 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5692 - accuracy: 0.6000\n",
      "Epoch 49: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.5692 - accuracy: 0.6000 - val_loss: 1.6486 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5684 - accuracy: 0.6000\n",
      "Epoch 50: val_loss did not improve from 1.61024\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.5684 - accuracy: 0.6000 - val_loss: 1.6494 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.6094 - accuracy: 0.2000\n",
      "test accuracy: 20.0%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment():\n",
    "    filepath='./tmp/video_classifier'\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath,save_weights_only=True, save_best_only=True,verbose=1)\n",
    "    \n",
    "    \n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "      [train_data[0],train_data[1]],\n",
    "      train_labels,\n",
    "      validation_split=0.3,\n",
    "      epochs=EPOCHS,\n",
    "      callbacks=[checkpoint],)\n",
    "    seq_model.load_weights(filepath)\n",
    "    _,accuracy = seq_model.evaluate([test_data[0],test_data[1]],[test_labels])\n",
    "    print(f'test accuracy: {round(accuracy * 100,2)}%')\n",
    "    \n",
    "    return history, seq_model\n",
    "_,sequence_model = run_experiment()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec98f188-ac10-4294-8267-0ddb7579996a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None,...]\n",
    "    frame_mask = np.zeros(shape=(1,MAX_SEQ_LENGTH,),dtype='bool')\n",
    "    frame_features =np.zeros(shape=(1,MAX_SEQ_LENGTH,NUM_FEATURES),dtype='float32')\n",
    "    \n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length= min(MAX_SEQ_LENGTH,video_length)\n",
    "        for j in range(length):\n",
    "            frame_feature[i,j,:]= feature_extractor.predict(batch[None,j,:])\n",
    "        frame_mask[i,:length]=1\n",
    "    return frame_features,frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e43263-901c-49f2-8d31-0e963fb8310d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path :dataset1/test/exercise/WhatsApp Video 2024-04-09 at 3.35.40 PM.mp4\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "abnormal:20.02%\n",
      "dance:20.02%\n",
      "exercise:19.98%\n",
      "yoga:19.98%\n",
      "normal:19.98%\n"
     ]
    }
   ],
   "source": [
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    frames = load_video(os.path.join(\"test\",path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "    \n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f'{class_vocab[i]}:{probabilities[i]* 100:5.2f}%')\n",
    "    return frames\n",
    "test_video = np.random.choice(test_df['video_name'].values.tolist())\n",
    "print(f'Test video path :{test_video}')\n",
    "\n",
    "test_frames = sequence_prediction(test_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e181b045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"dataset1/test/normal/WhatsApp Video 2024-04-09 at 3.35.40 PM.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "video_path='dataset1/test/normal/WhatsApp Video 2024-04-09 at 3.35.40 PM.mp4'\n",
    "Video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48584d2e-d5f6-4c64-bd58-38e4a26a66fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m     feature_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# 10-dimensional feature vector\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_vector\n\u001b[1;32m---> 11\u001b[0m extract_gait_features(frames)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c10623ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "abnormal:20.02%\n",
      "dance:20.02%\n",
      "exercise:19.98%\n",
      "yoga:19.98%\n",
      "normal:19.98%\n",
      "Gait Similarity Score: 1.389465877321249\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define function to extract gait features\n",
    "def extract_gait_features(frames):\n",
    "    # Perform gait detection and extract features (e.g., motion patterns)\n",
    "    # This function should return a feature vector representing the gait\n",
    "\n",
    "    # Placeholder: Random feature vector for demonstration\n",
    "    feature_vector = np.random.rand(10)  # 10-dimensional feature vector\n",
    "    return feature_vector\n",
    "\n",
    "# Define function to compare gait similarity\n",
    "def compare_gait(gait_features1, gait_features2):\n",
    "    # Compute Euclidean distance between feature vectors\n",
    "    similarity_score = np.linalg.norm(gait_features1 - gait_features2)\n",
    "    return similarity_score\n",
    "\n",
    "# Load and process gait videos for person 1 and person 2\n",
    "video_path_person1 = \"snehal.mp4\"\n",
    "# video_path_person2 = \"snehal.mp4\"\n",
    "\n",
    "gait_frames_person1 = sequence_prediction(video_path_person1)\n",
    "# gait_frames_person2 = sequence_prediction(video_path_person2)\n",
    "\n",
    "# Extract gait features for each person\n",
    "gait_features_person1 = extract_gait_features(gait_frames_person1)\n",
    "# gait_features_person2 = extract_gait_features(gait_frames_person2)\n",
    "\n",
    "# Compare gait similarity\n",
    "similarity_score = compare_gait(gait_features_person1, gait_features_person2)\n",
    "\n",
    "# Visualize similarity score\n",
    "print(\"Gait Similarity Score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "087c08d7-e63d-4d0f-b587-d55132294f84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\RUSHAB\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "1/1 [==============================] - 1s 572ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "Feature shape: (123, 25088)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def extract_video_features(video_path):\n",
    "    # Load pre-trained VGG16 model\n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    \n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Check if the video file opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file.\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize an empty list to store features\n",
    "    features = []\n",
    "    \n",
    "    # Iterate through each frame in the video\n",
    "    while cap.isOpened():\n",
    "        # Read the next frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Check if the frame was read successfully\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Resize the frame to fit VGG16 input size (224x224)\n",
    "        resized_frame = cv2.resize(frame, (224, 224))\n",
    "        \n",
    "        # Preprocess the frame for VGG16 model\n",
    "        processed_frame = preprocess_input(np.expand_dims(resized_frame, axis=0))\n",
    "        \n",
    "        # Extract features from the frame using VGG16 model\n",
    "        features.append(model.predict(processed_frame).flatten())  # Flatten the feature tensor\n",
    "        \n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Example usage:\n",
    "video_path = \"snehal.mp4\"\n",
    "video_features = extract_video_features(video_path)\n",
    "print(\"Feature shape:\", np.array(video_features).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab9d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cfb62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9510096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a1b184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572b096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758078b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b583d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2dc80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d76900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b55aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1820ec77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578df52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d20688b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9638d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
